{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ed09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from queuerious_detector.preprocessing import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "raw_data = pd.read_csv(\n",
    "    \"../data/raw/aa_dataset-tickets-multi-lang-5-2-50-version.csv\")\n",
    "\n",
    "#combine classes based on previous analysis\n",
    "class_map = {'Technical Support': 'Technical & IT Support',\n",
    "    'IT Support': 'Technical & IT Support',\n",
    "    'Customer Service': 'Customer Service, Returns & Exchanges',\n",
    "    'Returns and Exchanges': 'Customer Service, Returns & Exchanges'\n",
    "}\n",
    "\n",
    "#preprocess the data\n",
    "preprocess_data = preprocess_tickets(\n",
    "    df=raw_data,\n",
    "    text_fields=[\"subject\", \"body\"],\n",
    "    target_col=\"queue\",\n",
    "    new_target_col=\"queue_grouped\",\n",
    "    class_map=class_map,\n",
    "    output_columns=[\"combined_text\", \"queue_grouped\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f1887",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb01e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def redact_pii(text: Any, lang: str) -> str:\n",
    "    \"\"\"\n",
    "    Redact PII from text using regex and Named Entity Recognition (NER).\n",
    "\n",
    "    Regex:\n",
    "      - Emails\n",
    "      - Phone numbers\n",
    "      - IP addresses\n",
    "      - Credit card numbers\n",
    "      - Street-style addresses\n",
    "\n",
    "    NER:\n",
    "      - PERSON (names)\n",
    "\n",
    "    Args:\n",
    "        text (Any): Input text to redact.\n",
    "        lang (str): Language code ('en' or 'de') for appropriate NER model.\n",
    "\n",
    "    Returns:\n",
    "        str: Text with PII replaced by placeholders.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    redacted = text  # <- Define redacted here\n",
    "\n",
    "    patterns = {\n",
    "        \"email\": r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\",\n",
    "        \"phone\": (\n",
    "            r\"\\b(\\+?\\d{1,3}[-.\\s]?)?(\\(?\\d{3}\\)?|\\d{3})\"\n",
    "            r\"[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
    "        ),\n",
    "        \"ip\": r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\",\n",
    "        \"credit_card\": r\"\\b(?:\\d[ -]*?){13,16}\\b\",\n",
    "        \"address\": r\"\\b\\d{1,5}\\s+\\w+(?:\\s\\w+)?\\s+(St|Street|Ave|Avenue|Rd|Road|Blvd|Boulevard|Dr|Drive|Ln|Lane)\\b\",\n",
    "    }\n",
    "\n",
    "    for key, pattern in patterns.items():\n",
    "        redacted = re.sub(pattern, f\"[{key.upper()}_REDACTED]\", redacted)\n",
    "\n",
    "    nlp = nlp_en if lang == \"en\" else nlp_de if lang == \"de\" else None\n",
    "    if not nlp:\n",
    "        return redacted\n",
    "\n",
    "    # NER-based redaction\n",
    "    doc = nlp(redacted)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            redacted = redacted.replace(ent.text, \"<NAME>\")\n",
    "\n",
    "    return redacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668eb38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "raw_multi_df = pd.read_csv(\"../data/raw/aa_dataset-tickets-multi-lang-5-2-50-version.csv\")\n",
    "raw_multi_df.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the non-english records\n",
    "en_de_only_df = raw_multi_df[(raw_multi_df['language'] == \"en\") \n",
    "                             | (raw_multi_df['language'] == 'de')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add combined text column\n",
    "df_combo_text = combine_text_columns(en_de_only_df, [\"subject\", \"body\"])\n",
    "df_combo_text.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check for PII ->\n",
    "df_combo_text['PII_found'] = df_combo_text.apply(\n",
    "    lambda row: find_pii_patterns(row[\"Combined_Text_Col\"],\n",
    "                                   row[\"language\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937bfe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now redact PII\n",
    "df_combo_text['Redacted_Text'] = df_combo_text.apply(\n",
    "    lambda row: redact_pii(row[\"Combined_Text_Col\"],\n",
    "                                   row[\"language\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running this cell a few times to assess\n",
    "df_combo_text[[\"Combined_Text_Col\", \"PII_found\", \"Redacted_Text\"]].sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_text[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36988f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now translate combined text field to english -> I let this run for about 4hrs and it still has not completed.\n",
    "#df_combo_text[\"translated_text\"] = df_combo_text[\"Combined_Text_Col\"].apply(translate_to_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77df29c",
   "metadata": {},
   "source": [
    "### Lessons Learned:\n",
    "1. In viewing the \"Answer\" column I can see that the data was previously redacted, however it doesn't seem that \"body\" and \"subject\" were redacted.\n",
    "\n",
    "2. The redaction function will get added to the pipeline to help reduce pii in new data (production)\n",
    "\n",
    "3. I experimented the spacy Small models but had too many misclassifications, the Large models seem to perform better.\n",
    "\n",
    "4. One thing that increases missclassifications is the lack of context - for example the \"subject\" column alone may be too short for NER to be effective. I decided to combine the \"subject\" and \"body\" columns.\n",
    "\n",
    "5. Sometimes product is misclassified by Spacy NER - it's recognized as person entity\n",
    "\n",
    "6. One enhancement I would make is translation - the traslation function takes hours to implement since we have 12k german records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siads699",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
